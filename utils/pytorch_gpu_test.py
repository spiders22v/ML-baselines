"""
PyTorch ë° CUDA/GPU ìƒíƒœ í™•ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import platform

def test_python_version():
    """Python ë²„ì „ í™•ì¸"""
    print(f"ğŸ Python ë²„ì „: {sys.version}")
    print(f"ğŸ“‹ í”Œë«í¼: {platform.platform()}")
    print()

def test_pytorch():
    """PyTorch ì„¤ì¹˜ ë° ë²„ì „ í™•ì¸"""
    try:
        import torch
        print(f"ğŸ”¥ PyTorch ë²„ì „: {torch.__version__}")
        print(f"ğŸ“¦ PyTorch ê²½ë¡œ: {torch.__file__}")
        return True
    except ImportError as e:
        print(f"âŒ PyTorchë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return False

def test_cuda():
    """CUDA ì§€ì› ë° GPU ìƒíƒœ í™•ì¸"""
    try:
        import torch
        
        print("ğŸ” CUDA ì§€ì› ìƒíƒœ:")
        print(f"   - CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"   - CUDA ë²„ì „: {torch.version.cuda}")
            print(f"   - cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
            print(f"   - GPU ê°œìˆ˜: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"   - GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
                
            # í˜„ì¬ GPU ì„¤ì •
            if torch.cuda.device_count() > 0:
                current_device = torch.cuda.current_device()
                print(f"   - í˜„ì¬ GPU: {current_device}")
                
                # ê°„ë‹¨í•œ GPU ì—°ì‚° í…ŒìŠ¤íŠ¸
                print("   - GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì¤‘...")
                device = torch.device('cuda')
                x = torch.randn(1000, 1000).to(device)
                y = torch.randn(1000, 1000).to(device)
                z = torch.mm(x, y)
                print(f"   - GPU ì—°ì‚° ì„±ê³µ! ê²°ê³¼ í…ì„œ í¬ê¸°: {z.shape}")
        else:
            print("   - CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ CUDA í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def test_torchvision():
    """torchvision ì„¤ì¹˜ í™•ì¸"""
    try:
        import torchvision
        print(f"ğŸ–¼ï¸  torchvision ë²„ì „: {torchvision.__version__}")
        return True
    except ImportError:
        print("âŒ torchvisionì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

def test_torchaudio():
    """torchaudio ì„¤ì¹˜ í™•ì¸"""
    try:
        import torchaudio
        print(f"ğŸµ torchaudio ë²„ì „: {torchaudio.__version__}")
        return True
    except ImportError:
        print("âŒ torchaudioê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ PyTorch ë° GPU ìƒíƒœ ì¢…í•© í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print()
    
    # Python ë²„ì „ í™•ì¸
    test_python_version()
    
    # PyTorch í…ŒìŠ¤íŠ¸
    if test_pytorch():
        print()
        # CUDA/GPU í…ŒìŠ¤íŠ¸
        test_cuda()
        print()
        
        # ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í…ŒìŠ¤íŠ¸
        test_torchvision()
        test_torchaudio()
        print()
        
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê³„ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ PyTorchë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   pip install torch torchvision torchaudio")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
